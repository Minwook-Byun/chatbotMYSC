import streamlit as st
import os
import pandas as pd # pandasëŠ” ì§ì ‘ ì‚¬ìš©ë˜ì§€ ì•Šì§€ë§Œ, ì¼ë°˜ì ì¸ ë°ì´í„° ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ìœ ì§€í•©ë‹ˆë‹¤.
import sqlite3
import datetime

from langchain_core.documents import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_retrieval_chain
from langchain_community.callbacks import get_openai_callback

from langchain_community.document_loaders import (
    PyPDFLoader,
    UnstructuredExcelLoader,
    UnstructuredWordDocumentLoader,
    TextLoader,
    CSVLoader
)

# --- SQLite ë¡œê¹… ì„¤ì • ì¶”ê°€ ---
DB_NAME = 'token_usage.sqlite'
# USD/KRW í™˜ìœ¨ - ì˜ˆì‹œ ê°’ì…ë‹ˆë‹¤. ì‹¤ì œ í™˜ìœ¨ë¡œ ì—…ë°ì´íŠ¸í•˜ê±°ë‚˜, APIë¥¼ í†µí•´ ë™ì ìœ¼ë¡œ ê°€ì ¸ì˜¤ë„ë¡ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
USD_TO_KRW_EXCHANGE_RATE = 1370.00 # ì˜ˆì‹œ: 1 USD = 1370 KRW

def init_db():
    """ë°ì´í„°ë² ì´ìŠ¤ì™€ í…Œì´ë¸”ì„ ì´ˆê¸°í™”í•˜ê³ , í•„ìš”í•œ ê²½ìš° ìŠ¤í‚¤ë§ˆë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
    conn = sqlite3.connect(DB_NAME)
    cursor = conn.cursor()

    # í…Œì´ë¸” ìƒì„± (ì´ë¯¸ ì¡´ì¬í•˜ë©´ ìƒì„± ì•ˆ í•¨)
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS usage_logs (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
            business_name TEXT, 
            model_name TEXT NOT NULL,
            prompt_tokens INTEGER,
            completion_tokens INTEGER,
            total_tokens INTEGER NOT NULL,
            cost_usd REAL,
            cost_krw REAL,
            api_call_tag TEXT DEFAULT NULL
        )
    ''')

    # business_name ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš° ì¶”ê°€ (ê¸°ì¡´ DB í˜¸í™˜ì„±)
    cursor.execute("PRAGMA table_info(usage_logs)")
    columns = [info[1] for info in cursor.fetchall()]
    if 'business_name' not in columns:
        try:
            cursor.execute("ALTER TABLE usage_logs ADD COLUMN business_name TEXT")
            print("INFO: 'business_name' column added to 'usage_logs' table.")
        except sqlite3.OperationalError as e:
            # ì´ë¯¸ ì»¬ëŸ¼ì´ ì¶”ê°€ë˜ì—ˆê±°ë‚˜ ë‹¤ë¥¸ ë¬¸ì œ ë°œìƒ ì‹œ (ì˜ˆ: ë™ì‹œì„± ë¬¸ì œ)
            print(f"WARNING: Could not add 'business_name' column, it might already exist or another issue occurred: {e}")
    
    conn.commit()
    conn.close()

def log_token_usage(business_name, model_name, prompt_tokens, completion_tokens, total_tokens, cost_usd, api_call_tag=None):
    """í† í° ì‚¬ìš©ëŸ‰ ë° ë¹„ìš©ì„ SQLite ë°ì´í„°ë² ì´ìŠ¤ì— ê¸°ë¡í•©ë‹ˆë‹¤."""
    conn = sqlite3.connect(DB_NAME)
    cursor = conn.cursor()

    pt = prompt_tokens if prompt_tokens is not None and prompt_tokens >= 0 else None
    ct = completion_tokens if completion_tokens is not None and completion_tokens >= 0 else None
    tt = total_tokens if total_tokens is not None else 0

    cost_krw = None
    if cost_usd is not None:
        cost_krw = cost_usd * USD_TO_KRW_EXCHANGE_RATE
        cost_krw = round(cost_krw, 4) 

    try:
        cursor.execute('''
            INSERT INTO usage_logs (business_name, model_name, prompt_tokens, completion_tokens, total_tokens, cost_usd, cost_krw, api_call_tag)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        ''', (business_name, model_name, pt, ct, tt, cost_usd, cost_krw, api_call_tag))
        conn.commit()
        # print(f"Logged to DB: Business: {business_name}, Tag: {api_call_tag}, Model: {model_name}, Tokens: {tt}, Cost KRW: {cost_krw}")
    except sqlite3.Error as e:
        print(f"SQLite ë¡œê¹… ì˜¤ë¥˜: {e}") 
    finally:
        conn.close()

# --- End of SQLite ë¡œê¹… ì„¤ì • ---


# --- 0. OpenAI API í‚¤ ì„¤ì • ---
# OPENAI_API_KEY_INPUTì€ UIë¥¼ í†µí•´ ì‚¬ìš©ìê°€ ì…ë ¥í•©ë‹ˆë‹¤.

# --- ì‚¬ì—…ë³„ íšŒê³„ ì§€ì¹¨ íŒŒì¼ ê²½ë¡œ ---
GUIDELINE_FILES = {
    "ê²½ê¸° ì‚¬ê²½": "fixed_accounting_guideline.txt",
    "í•´ì–‘ìˆ˜ì‚°": "ocean.txt",
    "25-26 KOICA CTS": "CTS.txt"
}
# ê¸°ë³¸ê°’ìœ¼ë¡œ ì‚¬ìš©í•  ì§€ì¹¨ (ì˜ˆ: ì²« ë²ˆì§¸ í•­ëª©)
DEFAULT_BUSINESS_NAME = list(GUIDELINE_FILES.keys())[0]


# --- Helper Functions ---
@st.cache_resource
def get_embeddings_model(_api_key):
    if not _api_key:
        return None
    try:
        return OpenAIEmbeddings(model="text-embedding-ada-002", openai_api_key=_api_key)
    except Exception as e:
        st.error(f"ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨ (get_embeddings_model): {e}")
        return None

@st.cache_resource
def get_llm(_api_key):
    if not _api_key:
        return None
    try:
        return ChatOpenAI(model="gpt-4o", temperature=0, openai_api_key=_api_key)
    except Exception as e:
        st.error(f"LLM ë¡œë”© ì‹¤íŒ¨ (get_llm): {e}")
        return None

def load_document_from_local_path(file_path: str, uploaded_file_name_for_source: str = None):
    """ë¡œì»¬ ê²½ë¡œì˜ íŒŒì¼ì„ ë¡œë“œ (ê³ ì • ì§€ì¹¨ íŒŒì¼ ë¡œë“œìš© + ì—…ë¡œë“œ íŒŒì¼ ì²˜ë¦¬ìš©ìœ¼ë¡œ í†µí•© ê°€ëŠ¥)"""
    if not os.path.exists(file_path):
        st.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return None
    
    file_extension = os.path.splitext(file_path)[1].lower()
    loader = None
    source_name = uploaded_file_name_for_source if uploaded_file_name_for_source else os.path.basename(file_path)
    
    st.info(f"íŒŒì¼ ë¡œë”© ì‹œë„: {source_name} (í˜•ì‹: {file_extension})")

    if file_extension == ".pdf":
        loader = PyPDFLoader(file_path)
    elif file_extension in [".xlsx", ".xls"]:
        loader = UnstructuredExcelLoader(file_path, mode="elements")
    elif file_extension in [".docx", ".doc"]:
        loader = UnstructuredWordDocumentLoader(file_path, mode="elements")
    elif file_extension == ".csv":
        loader = CSVLoader(file_path=file_path, encoding="utf-8")
    elif file_extension == ".txt":
        loader = TextLoader(file_path, encoding="utf-8")
    else:
        st.error(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: {file_extension} ({source_name})")
        return None

    documents = None
    try:
        documents = loader.load()
        if not documents:
            st.write(f"loader.load() ê²°ê³¼ê°€ ë¹„ì–´ìˆê±°ë‚˜ Noneì…ë‹ˆë‹¤. ({source_name})")
        st.success(f"'{source_name}' íŒŒì¼ ë¡œë”© ì™„ë£Œ (1ì°¨ ì‹œë„): {len(documents) if documents else 0}ê°œì˜ Document ê°ì²´ ìƒì„±")
        for doc in documents:
            doc.metadata['source'] = source_name
        return documents
    except UnicodeDecodeError as ude:
        st.warning(f"UTF-8 ì¸ì½”ë”©ìœ¼ë¡œ '{source_name}' ë¡œë”© ì‹¤íŒ¨: {ude}. CP949ë¡œ ì¬ì‹œë„...")
        if file_extension == ".csv" or file_extension == ".txt":
            try:
                if file_extension == ".csv": loader = CSVLoader(file_path=file_path, encoding="cp949")
                else: loader = TextLoader(file_path, encoding="cp949")
                documents = loader.load()
                st.success(f"'{source_name}' íŒŒì¼ ë¡œë”© ì™„ë£Œ (CP949 ì¬ì‹œë„): {len(documents) if documents else 0}ê°œ Document ìƒì„±")
                for doc in documents: doc.metadata['source'] = source_name
                return documents
            except Exception as e2:
                st.error(f"CP949 ì¸ì½”ë”©ìœ¼ë¡œë„ '{source_name}' ë¡œë”© ì‹¤íŒ¨: {e2}")
                return None
        else: return None
    except Exception as e:
        st.error(f"'{source_name}' íŒŒì¼ ë¡œë”© ì¤‘ (ì¼ë°˜) ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def save_uploaded_file_to_temp(uploaded_file):
    """ì—…ë¡œë“œëœ íŒŒì¼ì„ ì„ì‹œ ë””ë ‰í† ë¦¬ì— ì €ì¥í•˜ê³  ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if uploaded_file is None: return None
    temp_dir = "temp_uploaded_files"
    os.makedirs(temp_dir, exist_ok=True)
    temp_file_path = os.path.join(temp_dir, uploaded_file.name)
    with open(temp_file_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    return temp_file_path


# --- Guideline Specific Resource Builders ---
@st.cache_resource(show_spinner="ì„ íƒëœ ì§€ì¹¨ ë¬¸ì„œ ì²˜ë¦¬ ì¤‘...")
def get_cached_guideline_vector_store(_embeddings_model, guideline_path, guideline_name):
    """ì„ íƒëœ ì§€ì¹¨ íŒŒì¼ë¡œë¶€í„° ë²¡í„° ì €ì¥ì†Œë¥¼ êµ¬ì¶•í•˜ê³  ìºì‹œí•©ë‹ˆë‹¤."""
    if not _embeddings_model:
        st.error("ì„ë² ë”© ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•„ ì§€ì¹¨ ë²¡í„° ì €ì¥ì†Œë¥¼ êµ¬ì¶•í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    if not os.path.exists(guideline_path):
        st.error(f"'{guideline_name}' ì§€ì¹¨ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {guideline_path}")
        return None
    
    st.info(f"ì§€ì¹¨ íŒŒì¼ ë¡œë”© ì‹œë„: {guideline_name} ({guideline_path})")
    guideline_documents = load_document_from_local_path(guideline_path, guideline_name)
    if not guideline_documents:
        st.error(f"'{guideline_name}' ì§€ì¹¨ ë¬¸ì„œ ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return None

    try:
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000, chunk_overlap=200, length_function=len, add_start_index=True
        )
        chunked_guideline_docs = text_splitter.split_documents(guideline_documents)
        if not chunked_guideline_docs:
            st.warning(f"'{guideline_name}' ì§€ì¹¨ ë¬¸ì„œê°€ ì²­í¬ë¡œ ë¶„í• ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
        
        st.info(f"'{guideline_name}' ì§€ì¹¨ ë¬¸ì„œ: {len(guideline_documents)}ê°œ ì›ë³¸ Doc -> {len(chunked_guideline_docs)}ê°œ ì²­í¬ ë¶„í•  ì™„ë£Œ.")
        vector_store = FAISS.from_documents(chunked_guideline_docs, _embeddings_model)
        st.success(f"'{guideline_name}' ì§€ì¹¨ ë²¡í„° ì €ì¥ì†Œ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        return vector_store
    except Exception as e:
        st.error(f"'{guideline_name}' ì§€ì¹¨ ë²¡í„° ì €ì¥ì†Œ êµ¬ì¶• ì‹¤íŒ¨: {e}")
        return None

@st.cache_resource 
def get_rag_chain_for_guideline(_guideline_vector_store, _llm, guideline_name_for_prompt):
    """ì£¼ì–´ì§„ ì§€ì¹¨ ë²¡í„° ì €ì¥ì†Œì™€ LLMì„ ì‚¬ìš©í•˜ì—¬ RAG ì²´ì¸ì„ ìƒì„±í•˜ê³  ìºì‹œí•©ë‹ˆë‹¤."""
    if not _guideline_vector_store or not _llm: return None
    retriever = _guideline_vector_store.as_retriever(search_kwargs={'k': 5})
    # --- MODIFIED PROMPT FOR EMPHASIS ---
    prompt_template_str = f"""
    ê·€í•˜ëŠ” "{guideline_name_for_prompt}" (ì´í•˜ "ë³¸ ê°€ì´ë“œë¼ì¸")ì— ëŒ€í•´ ì„¸ê³„ ìµœê³  ìˆ˜ì¤€ì˜ ì´í•´ë„ì™€ ì ìš© ëŠ¥ë ¥ì„ ê°–ì¶˜ AI ì£¼ì„ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. ê·€í•˜ì˜ ì£¼ëœ ì„ë¬´ëŠ” ì‚¬ìš©ìê°€ ì œê³µí•˜ëŠ” ëª¨ë“  í˜•íƒœì˜ ì…ë ¥(ë¬¸ì„œ ë‚´ìš© ë°œì·Œ, íŠ¹ì • ìƒí™© ê¸°ìˆ , ì§ì ‘ì ì¸ ì§ˆë¬¸, ì‚¬ì—… ê³„íš ì´ˆì•ˆ ë“±, ì´í•˜ "ì‚¬ìš©ì ì œì‹œ ë‚´ìš©")ì„ ë³¸ ê°€ì´ë“œë¼ì¸ì˜ ì¡°í•­, ê¸°ë³¸ ì›ì¹™, ëª©ì , ê·¸ë¦¬ê³  ìˆ¨ê²¨ì§„ í•¨ì˜ê¹Œì§€ ê³ ë ¤í•˜ì—¬ ì…ì²´ì ì´ê³  ì‹¬ì¸µì ìœ¼ë¡œ ë¶„ì„í•˜ê³ , ê·¸ ê²°ê³¼ë¥¼ ì‚¬ìš©ìì—ê²Œ ì „ë‹¬í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ê·€í•˜ëŠ” ë‹¨ìˆœ ì •ë³´ ì „ë‹¬ìê°€ ì•„ë‹Œ, ì‚¬ìš©ìì˜ ì„±ê³µì ì¸ ê°€ì´ë“œë¼ì¸ ì¤€ìˆ˜ë¥¼ ë•ê³  ì ì¬ì  ìœ„í—˜ìœ¼ë¡œë¶€í„° ë³´í˜¸í•˜ë©°, ìµœì ì˜ ì˜ì‚¬ê²°ì •ì„ ì§€ì›í•˜ëŠ” ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” í•µì‹¬ ì¡°ë ¥ìì…ë‹ˆë‹¤. ëª¨ë“  ë‹µë³€ì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ, ê·¹ë„ì˜ ìƒì„¸í•¨ê³¼ ëª…í™•ì„±, ê·¸ë¦¬ê³  ì‚¬ìš©ì ì¤‘ì‹¬ì˜ ì¹œì ˆí•¨ì„ ë‹´ì•„ ì œê³µë˜ì–´ì•¼ í•©ë‹ˆë‹¤.

    [í•µì‹¬ ìˆ˜í–‰ ì§€ì¹¨ ë° ë¶„ì„ í”„ë ˆì„ì›Œí¬]

    I. ì‚¬ìš©ì ì œì‹œ ë‚´ìš© ë¶„ì„ ë° ì˜ë„ íŒŒì•… ë‹¨ê³„:
    1. ì…ë ¥ ìœ í˜• ì‹ë³„: ì‚¬ìš©ì ì œì‹œ ë‚´ìš©ì´ ë‹¤ìŒ ì¤‘ ì–´ë–¤ ìœ í˜•ì— í•´ë‹¹í•˜ëŠ”ì§€ ì •í™•íˆ íŒë‹¨í•˜ì‹­ì‹œì˜¤.
        ê°€. íŠ¹ì • ë¬¸ì„œ/í…ìŠ¤íŠ¸/ê³„íšì•ˆì— ëŒ€í•œ ë³¸ ê°€ì´ë“œë¼ì¸ ë¶€í•© ì—¬ë¶€ ê²€í†  ìš”ì²­
        ë‚˜. íŠ¹ì • ê°€ìƒ ë˜ëŠ” ì‹¤ì œ ìƒí™©ì— ëŒ€í•œ ë³¸ ê°€ì´ë“œë¼ì¸ ì ìš© ë° í•´ì„ ì§ˆì˜
        ë‹¤. ë³¸ ê°€ì´ë“œë¼ì¸ íŠ¹ì • ì¡°í•­ ë˜ëŠ” ì „ì²´ ë‚´ìš©ì— ëŒ€í•œ ì§ì ‘ì ì¸ ì„¤ëª…/í•´ì„ ìš”ì²­
        ë¼. ë³¸ ê°€ì´ë“œë¼ì¸ ê´€ë ¨ ì ì¬ì  ë¬¸ì œì  ë˜ëŠ” ê¸°íšŒì— ëŒ€í•œ ìë¬¸ ìš”ì²­
        ë§ˆ. ê¸°íƒ€ (êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œ)
    2. í•µì‹¬ ìŸì  ë„ì¶œ: ì‚¬ìš©ì ì œì‹œ ë‚´ìš©ì—ì„œ ë³¸ ê°€ì´ë“œë¼ì¸ê³¼ ê´€ë ¨í•˜ì—¬ ê²€í† ê°€ í•„ìš”í•œ í•µì‹¬ ìŸì , ë¬¸ì œì , ë˜ëŠ” ì§ˆë¬¸ì‚¬í•­ì„ ëª…í™•í•˜ê²Œ ì¶”ì¶œí•˜ê³  ìš”ì•½í•˜ì‹­ì‹œì˜¤. ì‚¬ìš©ìê°€ ëª…ì‹œì ìœ¼ë¡œ ì§ˆë¬¸í•˜ì§€ ì•Šì•˜ë”ë¼ë„, ë‚´ìš©ìƒ ë³¸ ê°€ì´ë“œë¼ì¸ê³¼ ê´€ë ¨í•˜ì—¬ ì¤‘ìš”í•˜ê²Œ ë‹¤ë¤„ì ¸ì•¼ í•  ë¶€ë¶„ì´ ìˆë‹¤ë©´ ì´ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.

    II. ë³¸ ê°€ì´ë“œë¼ì¸ ê¸°ë°˜ ì‹¬ì¸µ ê²€í†  ë° ë¶„ì„ ë‹¨ê³„:
    3. ì¡°í•­ ë§¤ì¹­ ë° í•´ì„ì˜ ì •í™•ì„±:
        - ì‚¬ìš©ì ì œì‹œ ë‚´ìš©ê³¼ ê´€ë ¨ëœ ë³¸ ê°€ì´ë“œë¼ì¸ì˜ ëª¨ë“  ì¡°í•­(ì£¼ìš” ì¡°í•­, í•˜ìœ„ ì¡°í•­, ë³„í‘œ, ë¶€ì¹™ ë“± í¬í•¨)ì„ ì •í™•íˆ ì°¾ì•„ë‚´ê³  ëª©ë¡í™”í•˜ì‹­ì‹œì˜¤.
        - ê° ì¡°í•­ì˜ ë¬¸ì–¸ì  ì˜ë¯¸ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ í•˜ë˜, í•„ìš”í•œ ê²½ìš° í•´ë‹¹ ì¡°í•­ì˜ ì…ë²• ì·¨ì§€, ë³¸ ê°€ì´ë“œë¼ì¸ ì „ì²´ì˜ ì²´ê³„ì  ì§€ìœ„, ìœ ê´€ ì¡°í•­ê³¼ì˜ ê´€ê³„, ê·¸ë¦¬ê³  ê³¼ê±° ìœ ì‚¬ ì‚¬ë¡€(ì¡´ì¬í•œë‹¤ë©´)ê¹Œì§€ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í•˜ì—¬ ê°€ì¥ í•©ë¦¬ì ì´ê³  ì¼ê´€ëœ í•´ì„ì„ ë„ì¶œí•˜ì‹­ì‹œì˜¤.
        - í•´ì„ì˜ ì—¬ì§€ê°€ ìˆëŠ” ëª¨í˜¸í•œ ì¡°í•­ì— ëŒ€í•´ì„œëŠ” ê°€ëŠ¥í•œ ëª¨ë“  í•´ì„ê³¼ ê° í•´ì„ì— ë”°ë¥¸ ê²°ê³¼ë¥¼ ì œì‹œí•˜ê³ , ê·¸ì¤‘ ê°€ì¥ ì•ˆì „í•˜ê±°ë‚˜ ê¶Œì¥ë˜ëŠ” í•´ì„ì„ ëª…ì‹œí•˜ì‹­ì‹œì˜¤.
    4. ë¶€í•©/ìœ„ë°° ì—¬ë¶€ íŒë‹¨ ë° ìƒì„¸ ê·¼ê±° ì œì‹œ:
        - ê° ìŸì ë³„ë¡œ ì‚¬ìš©ì ì œì‹œ ë‚´ìš©ì´ ë³¸ ê°€ì´ë“œë¼ì¸ì˜ ê´€ë ¨ ì¡°í•­ì— ëª…í™•íˆ ë¶€í•©í•˜ëŠ”ì§€, ìœ„ë°°ë˜ëŠ”ì§€, ë˜ëŠ” ìœ„ë°°ì˜ ì†Œì§€ê°€ ìˆëŠ”ì§€ë¥¼ ëª…í™•íˆ íŒì •í•˜ì‹­ì‹œì˜¤.
        - ëª¨ë“  íŒë‹¨ì—ëŠ” ë°˜ë“œì‹œ ë³¸ ê°€ì´ë“œë¼ì¸ í…ìŠ¤íŠ¸ ë‚´ **ì •í™•í•œ ì¡°í•­ ë²ˆí˜¸(ì˜ˆ: ì œXì¡° ì œYí•­ ì œZí˜¸)ì™€ í•´ë‹¹ ì¡°í•­ì˜ ë‚´ìš©ì„ ì§ì ‘ ì¸ìš©**í•˜ì—¬ êµ¬ì²´ì ì¸ ê·¼ê±°ë¡œ ì œì‹œí•´ì•¼ í•©ë‹ˆë‹¤. (ì˜ˆ: "[ê´€ë ¨ ì§€ì¹¨ ê·¼ê±°: {guideline_name_for_prompt} ì œXì¡° ì œYí•­ - '...ì¡°í•­ ë‚´ìš© ì „ë¬¸ ë˜ëŠ” í•µì‹¬ ë¶€ë¶„ ì¸ìš©...']")
        - ë‹¨ìˆœíˆ ì¡°í•­ ë²ˆí˜¸ë§Œ ì–¸ê¸‰í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, í•´ë‹¹ ì¡°í•­ì´ ì™œ ì´ ì‚¬ì•ˆì— ì ìš©ë˜ëŠ”ì§€, ê·¸ë¦¬ê³  ê·¸ ì¡°í•­ì— ë”°ë¼ ì™œ ê·¸ëŸ¬í•œ íŒë‹¨ì„ ë‚´ë ¸ëŠ”ì§€ì— ëŒ€í•œ ìƒì„¸í•œ ë…¼ë¦¬ì  ì„¤ëª…ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
    5. ì ì¬ì  ìœ„í—˜ ìš”ì†Œ ë° ì£¼ì˜ì‚¬í•­ ë„ì¶œ (ì„ ì œì  ë¦¬ìŠ¤í¬ ê´€ë¦¬):
        - ì‚¬ìš©ì ì œì‹œ ë‚´ìš©ì´ í˜„ì¬ëŠ” ëª…ì‹œì ìœ¼ë¡œ ë³¸ ê°€ì´ë“œë¼ì¸ì— ìœ„ë°°ë˜ì§€ ì•Šë”ë¼ë„, í–¥í›„ ìƒí™© ë³€í™”ë‚˜ ì¡°ê±´ ì¶”ê°€ì— ë”°ë¼ ìœ„ë°°ë  ê°€ëŠ¥ì„±ì´ ìˆê±°ë‚˜, ë³¸ ê°€ì´ë“œë¼ì¸ì˜ ì •ì‹ ì— ë¶€í•©í•˜ì§€ ì•Šì„ ìˆ˜ ìˆëŠ” ëª¨ë“  ì ì¬ì  ìœ„í—˜ ìš”ì†Œ ë° ì£¼ì˜ì‚¬í•­ì„ ì² ì €íˆ ì‹ë³„í•˜ì—¬ ê²½ê³ í•´ì•¼ í•©ë‹ˆë‹¤.
        - "ë§Œì•½ ~í•œë‹¤ë©´", "íŠ¹íˆ ~ì˜ ê²½ìš°", "~ì„ ê°„ê³¼í•  ê²½ìš°" ë“±ì˜ í‘œí˜„ì„ ì‚¬ìš©í•˜ì—¬ êµ¬ì²´ì ì¸ ìƒí™©ì„ ê°€ì •í•˜ê³ , ë°œìƒ ê°€ëŠ¥í•œ ë¬¸ì œì ê³¼ ê·¸ë¡œ ì¸í•œ ë¶€ì •ì  ê²°ê³¼ë¥¼ ëª…í™•íˆ ì„¤ëª…í•˜ì‹­ì‹œì˜¤.
    6. ë³´ìˆ˜ì  ê²€í†  ì‹œë‚˜ë¦¬ì˜¤ ì˜ë¬´ ì œì‹œ:
        - ëª¨ë“  ê²€í†  ìš”ì²­ì— ëŒ€í•´, ê°€ì¥ ì—„ê²©í•œ ê¸°ì¤€ ë˜ëŠ” ë³´ìˆ˜ì ì¸ ê´€ì ì—ì„œ ë³¸ ê°€ì´ë“œë¼ì¸ì„ ì ìš©í–ˆì„ ê²½ìš° ë°œìƒí•  ìˆ˜ ìˆëŠ” ìµœì•…ì˜ ì‹œë‚˜ë¦¬ì˜¤ì™€ ê·¸ ê²°ê³¼ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•˜ì—¬ ì„¤ëª…í•´ì•¼ í•©ë‹ˆë‹¤. (ì˜ˆ: "**[ê°€ì¥ ë³´ìˆ˜ì ì¸ ê´€ì ì—ì„œì˜ ê²€í†  ì˜ê²¬]** í˜„ì¬ ì œì‹œëœ ë‚´ìš©ì´ Aì¡°ê±´ì„ ì¶©ì¡±í•˜ëŠ” ê²ƒìœ¼ë¡œ ë³´ì´ë‚˜, ë§Œì•½ ê°ë…ê¸°ê´€ì´ Bë¼ëŠ” ì¶”ê°€ ìë£Œë¥¼ ìš”êµ¬í•˜ë©° Aì¡°ê±´ì˜ ì¶©ì¡± ì—¬ë¶€ë¥¼ ë”ìš± ì—„ê²©í•˜ê²Œ ì‹¬ì‚¬í•  ê²½ìš°, ë³¸ ê°€ì´ë“œë¼ì¸ ì œYì¡° Zí•­ì˜ ì·¨ì§€ì— ë”°ë¼ 'ì¡°ê±´ ë¯¸ë¹„'ë¡œ íŒë‹¨ë  ê°€ëŠ¥ì„±ì„ ë°°ì œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì´ ê²½ìš°, <font color='red'>**ì‚¬ì—… ìŠ¹ì¸ ë°˜ë ¤ ë˜ëŠ” ê¸° ì§€ì›ê¸ˆ í™˜ìˆ˜ ë“±ì˜ ë¶ˆì´ìµì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.**</font>")
        - ì´ëŠ” ì‚¬ìš©ìê°€ ì˜ˆìƒì¹˜ ëª»í•œ ë¶ˆì´ìµì„ ë°©ì§€í•˜ê³ , ëª¨ë“  ê°€ëŠ¥ì„±ì„ ì—¼ë‘ì— ë‘” ì•ˆì „í•œ ì˜ì‚¬ê²°ì •ì„ ë‚´ë¦´ ìˆ˜ ìˆë„ë¡ ì§€ì›í•˜ê¸° ìœ„í•¨ì…ë‹ˆë‹¤.

    III. íŠ¹ìˆ˜ ì¡°ê±´ ì ìš© ë‹¨ê³„ (í•´ë‹¹ ì‹œ):
    7. "25-26 KOICA CTS" ê°€ì´ë“œë¼ì¸ (ì¦‰, "CTS.txt" íŒŒì¼) íŠ¹ìˆ˜ ì²˜ë¦¬:
        - ë§Œì•½ í˜„ì¬ ì ìš©ë˜ëŠ” `guideline_name_for_prompt`ê°€ **"25-26 KOICA CTS"** (ì¦‰, GUIDELINE_FILES ë”•ì…”ë„ˆë¦¬ì—ì„œ "CTS.txt" íŒŒì¼ì„ ê°€ë¦¬í‚¤ëŠ” í‚¤)ë¡œ ì§€ì •ëœ ê²½ìš°, ê·€í•˜ëŠ” ë‹¤ìŒì˜ ì¶”ê°€ ì§€ì¹¨ì„ ìµœìš°ì„ ì ìœ¼ë¡œ ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤:
            - ê·€í•˜ëŠ” "CTS.txt" ë¬¸ì„œì˜ **1799ë²ˆì§¸ ì¤„ë¶€í„° ì‹œì‘ë˜ëŠ” ê²ƒìœ¼ë¡œ ê°€ì •ë˜ëŠ” '[ FAQ ]' ì„¹ì…˜ì˜ ëª¨ë“  ë‚´ìš©ì„ ì™„ë²½í•˜ê²Œ ìˆ™ì§€**í•˜ê³  ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤. (ì‹¤ì œ ì¤„ ë²ˆí˜¸ëŠ” íŒŒì¼ ë‚´ìš©ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, í•´ë‹¹ í‘œì‹ì´ ìˆëŠ” ë¶€ë¶„ë¶€í„°ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.)
            - ì‚¬ìš©ì ì œì‹œ ë‚´ìš© ë˜ëŠ” ì§ˆë¬¸ì´ í•´ë‹¹ FAQ ì„¹ì…˜ì˜ ì‚¬ë¡€ì™€ ì¡°ê¸ˆì´ë¼ë„ ê´€ë ¨ì„±ì´ ìˆë‹¤ê³  íŒë‹¨ë  ê²½ìš°, **ë°˜ë“œì‹œ í•´ë‹¹ FAQì˜ ì§ˆë¬¸ê³¼ ë‹µë³€ ë‚´ìš©ì„ ëª…ì‹œì ìœ¼ë¡œ ì–¸ê¸‰í•˜ê³ , í˜„ì¬ ì‚¬ì•ˆê³¼ì˜ ìœ ì‚¬ì , ì°¨ì´ì , ê·¸ë¦¬ê³  ì‹œì‚¬ì ì„ ìƒì„¸íˆ ë¹„êµ ë¶„ì„í•˜ì—¬ ì„¤ëª…**í•´ì•¼ í•©ë‹ˆë‹¤. (ì˜ˆ: "**[CTS.txt FAQ ì‚¬ë¡€ ì—°ê´€ ê²€í† ]** ë³¸ ì‚¬ì•ˆì€ CTS.txt FAQ ì¤‘ 'Q. [FAQ ì§ˆë¬¸ ìš”ì•½]' ì‚¬ë¡€ì™€ ê´€ë ¨ì„±ì´ ë†’ìŠµë‹ˆë‹¤. í•´ë‹¹ FAQì—ì„œëŠ” '[FAQ ë‹µë³€ ìš”ì•½]'ìœ¼ë¡œ ì•ˆë‚´í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê·€í•˜ì˜ ìƒí™©ì€ [ìœ ì‚¬ì /ì°¨ì´ì  ì„¤ëª…] ì¸¡ë©´ì—ì„œ í•´ë‹¹ ì‚¬ë¡€ë¥¼ ì°¸ê³ í•˜ì—¬ [êµ¬ì²´ì  ì¡°ì–¸ ë˜ëŠ” í•´ì„]ì„ ê³ ë ¤í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            - FAQ ë‚´ìš©ì„ ë‹¨ìˆœíˆ ì „ë‹¬í•˜ëŠ” ê²ƒì„ ë„˜ì–´, í˜„ì¬ ì‚¬ìš©ì ìƒí™©ì— ë§ê²Œ ì¬í•´ì„í•˜ê³  ì ìš©í•˜ì—¬ ì‹¤ì§ˆì ì¸ ë„ì›€ì„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.
    8. TIPS í”„ë¡œê·¸ë¨ ê´€ë ¨ ì‚¬ì „ ê³ ì§€ ì˜ë¬´:
        - ì‚¬ìš©ì ì œì‹œ ë‚´ìš©ì—ì„œ "CTS-TIPS ì—°ê³„í˜• ì‚¬ì—…" ì§€ì› ë˜ëŠ” ì°¸ì—¬ì™€ ê´€ë ¨ëœ ë§¥ë½ì´ ì¡°ê¸ˆì´ë¼ë„ ê°ì§€ë  ê²½ìš° (ì‚¬ìš©ìê°€ ì§ì ‘ ì§ˆë¬¸í•˜ì§€ ì•Šë”ë¼ë„), ê·€í•˜ëŠ” ë‹¤ìŒì˜ ë‚´ìš©ì„ ë°˜ë“œì‹œ ëª…í™•í•˜ê³  ê°•ì¡°í•˜ì—¬ ì„ ì œì ìœ¼ë¡œ ì•ˆë‚´í•´ì•¼ í•©ë‹ˆë‹¤:
            - "**[TIPS í”„ë¡œê·¸ë¨ ê´€ë ¨ ì¤‘ìš” ê³ ì§€]** CTS-TIPS ì—°ê³„í˜• ì‚¬ì—… ì§€ì› ìê²©ê³¼ ê´€ë ¨í•˜ì—¬ ë§¤ìš° ì¤‘ìš”í•œ ì ì„ ì•ˆë‚´í•´ ë“œë¦½ë‹ˆë‹¤. <font color='red'>**TIPS í”„ë¡œê·¸ë¨ì˜ 'ì„±ê³µ' íŒì •ì€ ê³µì‹ì ìœ¼ë¡œ í•´ë‹¹ TIPS ê³¼ì œì˜ 'ì¢…ë£Œ'ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.**</font> ë”°ë¼ì„œ, ë§Œì•½ ê·€í•˜(ë˜ëŠ” ê·€ì‚¬)ê°€ í˜„ì¬ TIPS í”„ë¡œê·¸ë¨ì— ì°¸ì—¬ ì¤‘ì´ì‹œë¼ë©´, CTS-TIPS ì—°ê³„í˜• ì‚¬ì—…ì˜ ê³µëª¨ ì§€ì› ë§ˆì§€ë§‰ ë‚ (ë§ˆê°ì¼)ê¹Œì§€ í˜„ì¬ ìˆ˜í–‰ ì¤‘ì¸ TIPS ê³¼ì œê°€ ê³µì‹ì ìœ¼ë¡œ 'ì¢…ë£Œ(ì„±ê³µ)' ì²˜ë¦¬ë˜ì§€ ì•Šì€ ìƒíƒœë¼ë©´, ì•ˆíƒ€ê¹ê²Œë„ CTS-TIPS ì—°ê³„í˜• ì‚¬ì—…ì˜ ì§€ì› ìê²© ìš”ê±´ì„ ì¶©ì¡±í•˜ì§€ ëª»í•˜ëŠ” ê²ƒìœ¼ë¡œ ê°„ì£¼ë˜ì–´ <font color='red'>**ì§€ì›ì´ ë¶ˆê°€í•©ë‹ˆë‹¤.**</font> ì´ ì ì„ ë°˜ë“œì‹œ ìœ ë…í•˜ì‹œì–´ ë¶ˆì´ìµì„ ë°›ëŠ” ì¼ì´ ì—†ë„ë¡ ì‚¬ì „ì— TIPS ê³¼ì œ ì¢…ë£Œ ì¼ì •ì„ ì² ì €íˆ í™•ì¸í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
            - ì´ ì•ˆë‚´ëŠ” ì‚¬ìš©ìì˜ ì ì¬ì ì¸ ìê²© ë¯¸ë‹¬ ë¦¬ìŠ¤í¬ë¥¼ ìµœì†Œí™”í•˜ê¸° ìœ„í•œ í•„ìˆ˜ ì¡°ì¹˜ì…ë‹ˆë‹¤.

    IV. ë‹µë³€ êµ¬ì„± ë° ì „ë‹¬ ë‹¨ê³„:
    9. ë‹µë³€ì˜ êµ¬ì¡°í™” ë° ëª…ë£Œì„±:
        - ëª¨ë“  ë‹µë³€ì€ ë…¼ë¦¬ì  íë¦„ì— ë”°ë¼ ëª…í™•í•˜ê²Œ êµ¬ì¡°í™”ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ê¶Œì¥ êµ¬ì¡°ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.
            1.  **ì§ˆì˜/ìš”ì²­ì‚¬í•­ ì¬í™•ì¸ ë° ë¶„ì„ ê°œìš”:** ì‚¬ìš©ìì˜ ì…ë ¥ ë‚´ìš©ì„ ê°„ëµíˆ ìš”ì•½í•˜ê³ , ì–´ë–¤ ê´€ì ì—ì„œ ë³¸ ê°€ì´ë“œë¼ì¸ì„ ê²€í† í•  ê²ƒì¸ì§€ ëª…ì‹œí•©ë‹ˆë‹¤.
            2.  **ì¢…í•© ê²€í†  ì˜ê²¬ (ê²°ë¡  ìš”ì•½):** ê°€ì¥ í•µì‹¬ì ì¸ ê²°ë¡ (ì˜ˆ: **ë¶€í•©**, <font color='red'>**ì¼ë¶€ ìœ„ë°°**</font>, **ì¶”ê°€ í™•ì¸ í•„ìš”** ë“±)ì„ ë¨¼ì € ì œì‹œí•˜ì—¬ ì‚¬ìš©ìê°€ ë¹ ë¥´ê²Œ ê²°ê³¼ë¥¼ íŒŒì•…í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
            3.  **ì„¸ë¶€ ê²€í†  ë‚´ìš© ë° ê·¼ê±° ì¡°í•­:**
                * ê° ìŸì  ë˜ëŠ” í•­ëª©ë³„ë¡œ ë³¸ ê°€ì´ë“œë¼ì¸ê³¼ì˜ ë¶€í•©/ìœ„ë°° ì—¬ë¶€ ìƒì„¸ ë¶„ì„
                * ê° íŒë‹¨ì— ëŒ€í•œ ë³¸ ê°€ì´ë“œë¼ì¸ì˜ **ì •í™•í•œ ì¡°í•­ ë²ˆí˜¸ ë° ë‚´ìš© ì¸ìš©**
                * ì¡°í•­ í•´ì„ì— ëŒ€í•œ ìƒì„¸ ì„¤ëª…
            4.  **ì£¼ìš” ì£¼ì˜ì‚¬í•­ ë° ì ì¬ì  ìœ„í—˜ ìš”ì†Œ:** ì‹ë³„ëœ ìœ„í—˜ ìš”ì†Œì™€ ì£¼ì˜í•´ì•¼ í•  ì ë“¤ì„ **êµµê²Œ** ëª…ì‹œí•©ë‹ˆë‹¤. íŠ¹íˆ ìœ„í—˜ë„ê°€ ë†’ë‹¤ê³  íŒë‹¨ë˜ëŠ” ë¶€ë¶„ì€ <font color='red'>**êµµì€ ë¹¨ê°„ìƒ‰ ê¸€ì”¨**</font>ë¡œ ê°•ì¡°í•©ë‹ˆë‹¤.
            5.  **ë³´ìˆ˜ì  ê²€í†  ì‹œë‚˜ë¦¬ì˜¤ ë° ëŒ€ì‘ ë°©ì•ˆ ì œì–¸:** ê°€ì¥ ì—„ê²©í•œ ê¸°ì¤€ ì ìš© ì‹œ ë°œìƒ ê°€ëŠ¥í•œ ìƒí™©ê³¼ ì´ì— ëŒ€í•œ ì‚¬ìš©ìì˜ ê³ ë ¤ ì‚¬í•­ ë˜ëŠ” ëŒ€ì‘ ë°©ì•ˆì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ë¶€ë¶„ì˜ ê²½ê³ ëŠ” <font color='red'>**êµµì€ ë¹¨ê°„ìƒ‰ ê¸€ì”¨**</font>ë¡œ í‘œì‹œí•´ì£¼ì‹­ì‹œì˜¤.
            6.  **íŠ¹ìˆ˜ ì¡°ê±´ ê´€ë ¨ ë‚´ìš© (í•´ë‹¹ ì‹œ):** CTS.txt FAQ ì—°ê´€ ë¶„ì„ ë˜ëŠ” TIPS í”„ë¡œê·¸ë¨ ê´€ë ¨ ê³ ì§€ ì‚¬í•­ì„ í¬í•¨í•©ë‹ˆë‹¤.
            7.  **ê²°ë¡  ë° ê¶Œê³  ì‚¬í•­:** ì „ì²´ ê²€í†  ë‚´ìš©ì„ ìš”ì•½í•˜ê³ , ì‚¬ìš©ìì—ê²Œ í•„ìš”í•œ ë‹¤ìŒ í–‰ë™(ì˜ˆ: **ì¶”ê°€ ì •ë³´ ì œê³µ ìš”ì²­**, **ì „ë¬¸ê°€ ìë¬¸ ê¶Œìœ **, **ê³„íš ìˆ˜ì • ì œì•ˆ** ë“±)ì„ ëª…í™•íˆ ì•ˆë‚´í•©ë‹ˆë‹¤.
        - í•„ìš”ì— ë”°ë¼ í‘œ, ê¸€ë¨¸ë¦¬ ê¸°í˜¸ ë“±ì„ í™œìš©í•˜ì—¬ ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì „ë‹¬í•˜ì‹­ì‹œì˜¤.
        - ë‹µë³€ ë‚´ìš© ì¤‘ íŠ¹íˆ ì¤‘ìš”í•˜ë‹¤ê³  íŒë‹¨ë˜ëŠ” í•µì‹¬ ì‚¬í•­, ìœ„ë°˜ ê°€ëŠ¥ì„±ì´ ë†’ì€ ë¶€ë¶„, ì‚¬ìš©ìì—ê²Œ ë¶ˆì´ìµì´ ê°ˆ ìˆ˜ ìˆëŠ” ê²½ê³ , ë˜ëŠ” ë°˜ë“œì‹œ í™•ì¸í•´ì•¼ í•  ê¶Œê³  ì‚¬í•­ì— ëŒ€í•´ì„œëŠ” **êµµì€ ê¸€ì”¨(Bold)**ë¡œ ê°•ì¡°í•˜ê³ , ê·¸ì¤‘ì—ì„œë„ ìœ„í—˜ë„ê°€ ë†’ê±°ë‚˜ ì¦‰ê°ì ì¸ ì£¼ì˜ê°€ í•„ìš”í•œ ì‹¬ê°í•œ ì‚¬ì•ˆì— ëŒ€í•´ì„œëŠ” **<font color='red'>êµµì€ ê¸€ì”¨ì™€ í•¨ê»˜ ë¹¨ê°„ìƒ‰ ê¸€ì”¨</font>** (ì˜ˆ: `<font color='red'>**ì´ ë¶€ë¶„ì€ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤.**</font>`)ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª…í™•íˆ êµ¬ë¶„ë  ìˆ˜ ìˆë„ë¡ í•´ì£¼ì‹­ì‹œì˜¤. ì´ëŠ” ì‚¬ìš©ìê°€ ë‹µë³€ì˜ í•µì‹¬ì„ ë¹ ë¥´ê²Œ íŒŒì•…í•˜ê³  ì¤‘ìš”í•œ ì •ë³´ë¥¼ ë†“ì¹˜ì§€ ì•Šë„ë¡ í•˜ê¸° ìœ„í•¨ì…ë‹ˆë‹¤.
    10. ì‚¬ìš©ì ì¤‘ì‹¬ì˜ ì†Œí†µ:
        - ë‹µë³€ì€ í•­ìƒ ì‚¬ìš©ìì˜ ì…ì¥ì—ì„œ ì´í•´í•˜ê¸° ì‰½ë„ë¡ í‰ì´í•˜ê³  ëª…í™•í•œ ìš©ì–´ë¥¼ ì‚¬ìš©í•˜ë˜, ì „ë¬¸ì„±ì´ í•„ìš”í•œ ë¶€ë¶„ì—ì„œëŠ” ìš©ì–´ ì •ì˜ë¥¼ í•¨ê»˜ ì œê³µí•˜ì‹­ì‹œì˜¤.
        - ê·¹ë„ë¡œ ì •ì¤‘í•˜ê³  ê³µê°í•˜ëŠ” ì–´ì¡°ë¥¼ ìœ ì§€í•˜ë©°, ì‚¬ìš©ìê°€ ë§ˆì¹˜ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì „ë¬¸ê°€ì™€ ëŒ€í™”í•˜ê³  ìˆë‹¤ê³  ëŠë‚„ ìˆ˜ ìˆë„ë¡ í•˜ì‹­ì‹œì˜¤.
        - ì •ë³´ì˜ ë‚˜ì—´ì´ ì•„ë‹Œ, ì‚¬ìš©ìì˜ ì‹¤ì œì ì¸ ë¬¸ì œ í•´ê²°ê³¼ ì˜ì‚¬ê²°ì •ì— ë„ì›€ì´ ë˜ëŠ” ë°©í–¥ìœ¼ë¡œ ë‚´ìš©ì„ êµ¬ì„±í•˜ê³  ì „ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤.
        - ë‹µë³€ ë§ë¯¸ì—ëŠ” ì‚¬ìš©ìê°€ ì¶”ê°€ì ì¸ ì§ˆë¬¸ì´ë‚˜ ëª…í™•í™” ìš”ì²­ì„ í•  ìˆ˜ ìˆë„ë¡ ìì—°ìŠ¤ëŸ½ê²Œ ìœ ë„í•˜ëŠ” ë¬¸ì¥ì„ í¬í•¨í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. (ì˜ˆ: "ì´ ì™¸ì—ë„ ê¶ê¸ˆí•˜ì‹  ì ì´ë‚˜ ë” ìì„¸í•œ ì„¤ëª…ì´ í•„ìš”í•œ ë¶€ë¶„ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë‹¤ì‹œ ë¬¸ì˜í•´ ì£¼ì‹­ì‹œì˜¤.")
    11. fixed_accounting_guideline.txtì— ëŒ€í•œ íŠ¹ìˆ˜ì²˜ë¦¬ 
        - ì¤‘ìš”í•œ ì‚¬ì•ˆìœ¼ë¡œ, ì¸í”Œë£¨ì–¸ì„œ ë§ˆì¼€íŒ… ë“±ì€ í™ë³´ë§ˆì¼€íŒ…ë¹„ë¡œ ì²˜ë¦¬í•´ì•¼ í•¨. ì™¸ì£¼ìš©ì—­ì„ ë§¡ê¸°ëŠ” ê²ƒì´ê¸° ë•Œë¬¸ì— ì¸ìŠ¤íƒ€ê·¸ë¨, ì¿ íŒ¡, ìœ íŠœë¸Œ ë“±ì˜ ê´‘ê³  ë§ˆì¼€íŒ…ë¹„ëŠ” í™ë³´ë§ˆì¼€íŒ…ë¹„ê°€ ì•„ë‹Œ ì „ë¬¸ê°€ í™œìš©ë¹„ì„. 
        - ì¤‘ìš”í•œ ì‚¬ì•ˆìœ¼ë¡œ, ì‚¬ì—…ë¹„/ì§€ì›ê¸ˆ ê³„íšì„ ê²€í† í•  ë•ŒëŠ” ê¸°ì—…ì˜ ì‚¬ìš© ë°©ì‹ì„ í•œ ë²ˆ ì´ì•¼ê¸°í•´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤. ê·¸ë¦¬ê³  ì´ì–´ì„œ ê´€ë ¨ ì§€ì¹¨ì„ ì´ì•¼ê¸°í•´ì£¼ê³  ë„¤ê°€ íŒë‹¨í•œ ê·¼ê±°ë¥¼ ì´ì•¼ê¸° í•´ì•¼ í•©ë‹ˆë‹¤. (ì˜ˆ: ì œë¯¸ë‚˜ì´ëŠ” ì‚¬ì—…ë¹„ ê³„íšì„ ì „ë¬¸ê°€ í™œìš©ì— 50% ì´ìƒ í™œìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê°€ì´ë“œ ìƒ ê·¸ëŸ¬í•œ ì‚¬ìš©ì€ ê°€ëŠ¥/ë¶ˆê°€ëŠ¥í•˜ë©° ì´ë¡œ ì¸í•´ì„œ ì í•©/ë¶€ì í•©í•©ë‹ˆë‹¤.)

    [ì§€ì†ì  í•™ìŠµ ë° ê°œì„  ì˜ë¬´]
    ê·€í•˜ëŠ” ë³¸ ê°€ì´ë“œë¼ì¸ ë° ê´€ë ¨ ê·œì •, ì§€ì¹¨ ë“±ì˜ ë³€ê²½ ì‚¬í•­ì— ëŒ€í•´ í•­ìƒ ìµœì‹  ì •ë³´ë¥¼ ìœ ì§€í•´ì•¼ í•˜ë©°, ì‚¬ìš©ìì™€ì˜ ìƒí˜¸ì‘ìš©ì„ í†µí•´ ìˆ˜ì§‘ëœ ë‹¤ì–‘í•œ ì‚¬ë¡€ì™€ í”¼ë“œë°±ì„ ë°”íƒ•ìœ¼ë¡œ ë¶„ì„ ëŠ¥ë ¥ê³¼ ë‹µë³€ì˜ ì§ˆì„ ì§€ì†ì ìœ¼ë¡œ í–¥ìƒì‹œì¼œì•¼ í•  ì˜ë¬´ê°€ ìˆìŠµë‹ˆë‹¤.
    
    [ê´€ë ¨ ì§€ì¹¨ ë‚´ìš©]
    {{context}}

    [ì‚¬ìš©ì ì œê³µ ë‚´ìš© ë° ì§ˆë¬¸]
    {{input}}

    [ê²€í†  ì˜ê²¬ ë° ë‹µë³€]
    """
    prompt = ChatPromptTemplate.from_template(prompt_template_str)
    document_chain = create_stuff_documents_chain(_llm, prompt)
    return create_retrieval_chain(retriever, document_chain)


# --- Uploaded Document Specific Resource Builders ---
@st.cache_resource(show_spinner="ì—…ë¡œë“œëœ ë¬¸ì„œ ì²˜ë¦¬ ì¤‘ (Q&Aìš©)...")
def build_generic_vector_store_for_qa(_docs_for_qa, _embeddings_model, file_name_for_log, cache_key_tuple):
    """
    ì—…ë¡œë“œëœ ë¬¸ì„œë¡œë¶€í„° Q&Aìš© ì¼ë°˜ ë²¡í„° ì €ì¥ì†Œë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤.
    _docs_for_qaëŠ” Streamlit ìºì‹±ì—ì„œ ì œì™¸ë˜ë©°, cache_key_tupleì´ ìºì‹œì˜ ì£¼ìš” ì‹ë³„ì ì—­í• ì„ í•©ë‹ˆë‹¤.
    """
    if not _embeddings_model:
        st.error("ì„ë² ë”© ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•„ Q&Aìš© ë²¡í„° ì €ì¥ì†Œë¥¼ êµ¬ì¶•í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    if not _docs_for_qa: 
        st.warning(f"'{file_name_for_log}'ì—ì„œ Q&Aë¥¼ ìœ„í•œ ë¬¸ì„œë¥¼ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return None
    try:
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000, chunk_overlap=200, length_function=len, add_start_index=True
        )
        chunked_qa_docs = text_splitter.split_documents(_docs_for_qa) 
        if not chunked_qa_docs:
            st.warning(f"'{file_name_for_log}' ë¬¸ì„œê°€ Q&Aë¥¼ ìœ„í•´ ì²­í¬ë¡œ ë¶„í• ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
        
        st.info(f"ì—…ë¡œë“œ ë¬¸ì„œ ('{file_name_for_log}') Q&Aìš©: {len(_docs_for_qa)}ê°œ ì›ë³¸ Doc -> {len(chunked_qa_docs)}ê°œ ì²­í¬ ë¶„í• .")
        vector_store = FAISS.from_documents(chunked_qa_docs, _embeddings_model)
        st.success(f"'{file_name_for_log}' ë¬¸ì„œ ê¸°ë°˜ Q&Aìš© ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì™„ë£Œ.")
        return vector_store
    except Exception as e:
        st.error(f"'{file_name_for_log}' ë¬¸ì„œ Q&Aìš© ë²¡í„° ì €ì¥ì†Œ êµ¬ì¶• ì‹¤íŒ¨: {e}")
        return None

@st.cache_resource
def get_document_qa_rag_chain(_vector_store, _llm, document_name_for_prompt):
    """ì—…ë¡œë“œëœ ë¬¸ì„œ Q&Aìš© RAG ì²´ì¸ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    if not _vector_store or not _llm: return None
    retriever = _vector_store.as_retriever(search_kwargs={'k': 3})
    # --- MODIFIED PROMPT FOR EMPHASIS ---
    prompt_template_str = f"""
    ë‹¹ì‹ ì€ '{document_name_for_prompt}' ë¬¸ì„œì˜ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
    ë¬¸ì„œ ë‚´ìš©ì„ ì¶©ì‹¤íˆ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”. ì œê³µëœ ë¬¸ì„œì—ì„œ ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´, ë¬¸ì„œì—ì„œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ë‹¤ê³  ëª…í™•íˆ ë°í˜€ì£¼ì„¸ìš”.
    ë‹¹ì‹ ì´ íŒë‹¨í•œ ê·¼ê±°ì™€ txt ìƒì˜ ê´€ë ¨ ì¡°í•­ì„ ê°™ì´ ì¶œë ¥í•´ì£¼ì„¸ìš”. 
    ë‹µë³€ ë‚´ìš© ì¤‘ íŠ¹íˆ ì¤‘ìš”í•˜ë‹¤ê³  íŒë‹¨ë˜ëŠ” ë¶€ë¶„ì´ë‚˜ ì‚¬ìš©ìì—ê²Œ ì£¼ì˜ê°€ í•„ìš”í•œ ë‚´ìš©ì€ **êµµì€ ê¸€ì”¨**ë¡œ ê°•ì¡°í•˜ê³ , ìœ„í—˜ë„ê°€ ë†’ê±°ë‚˜ ì¹˜ëª…ì ì¸ ë¬¸ì œë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆëŠ” ë‚´ìš©ì€ **<font color='red'>êµµì€ ë¹¨ê°„ìƒ‰ ê¸€ì”¨</font>**ë¡œ ê°•ì¡°í•˜ì—¬ ì‚¬ìš©ìê°€ ì‰½ê²Œ ì¸ì§€í•  ìˆ˜ ìˆë„ë¡ í•´ì£¼ì„¸ìš”.
    íŠ¹íˆë‚˜ ë³´ìˆ˜ì  ê²€í† í•œ ì‹œë‚˜ë¦¬ì˜¤ë„ ê¼­ ê°™ì´ ë³´ì—¬ì¤˜ì„œ íˆ¬ëª…í•œ ì§‘í–‰ ì˜ì‚¬ê²°ì •ì— ë„ì›€ì´ ë  ìˆ˜ ìˆë„ë¡ í•´ì£¼ì„¸ìš”. ì´ ê²½ìš°, ë³´ìˆ˜ì  ì‹œë‚˜ë¦¬ì˜¤ì— ë”°ë¥¸ ì ì¬ì  ë¶€ì •ì  ê²°ê³¼ëŠ” **<font color='red'>êµµì€ ë¹¨ê°„ìƒ‰ ê¸€ì”¨</font>**ë¡œ ê°•ì¡°í•´ì£¼ì‹­ì‹œì˜¤.
    ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ìƒì„¸í•˜ê³  ì¹œì ˆí•˜ê²Œ í•´ì£¼ì„¸ìš”.

    [ë¬¸ì„œ ë‚´ìš© ì¤‘ ê´€ë ¨ ë¶€ë¶„]
    {{context}}

    [ì‚¬ìš©ì ì§ˆë¬¸]
    {{input}}

    [ë‹µë³€]
    """
    prompt = ChatPromptTemplate.from_template(prompt_template_str)
    document_chain = create_stuff_documents_chain(_llm, prompt)
    return create_retrieval_chain(retriever, document_chain)


# --- Streamlit UI êµ¬ì„± ---
st.set_page_config(page_title="ë¬¸ì„œ ìë™ ê²€í†  AI", layout="wide")
st.title("ë¬¸ì„œ ìë™ ê²€í†  ë° ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ ğŸ¤–")

# SQLite DB ì´ˆê¸°í™”
init_db()

OPENAI_API_KEY_INPUT = st.text_input(
    "OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", type="password", key="api_key_main_input",
    placeholder="sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
)

if not OPENAI_API_KEY_INPUT:
    st.warning("OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì•¼ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    st.stop()

embeddings_model_global = get_embeddings_model(OPENAI_API_KEY_INPUT)
llm_global = get_llm(OPENAI_API_KEY_INPUT)

if not embeddings_model_global or not llm_global:
    st.error("OpenAI ëª¨ë¸(ì„ë² ë”© ë˜ëŠ” LLM) ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()
else:
    st.success(f"OpenAI ëª¨ë¸ ë¡œë”© ì™„ë£Œ (LLM: {llm_global.model_name}).")


st.markdown("---")

selected_business_name_from_selectbox = st.selectbox( # ë³€ìˆ˜ëª… ë³€ê²½ìœ¼ë¡œ ëª…í™•í™”
    "ê²€í†  ê¸°ì¤€ì´ ë  ì‚¬ì—…ì„ ì„ íƒí•˜ì„¸ìš”:",
    options=list(GUIDELINE_FILES.keys()),
    key="business_selection_selectbox",
    index=list(GUIDELINE_FILES.keys()).index(st.session_state.get("selected_business_name_stored", DEFAULT_BUSINESS_NAME))
)

if selected_business_name_from_selectbox: # ë³€ê²½ëœ ë³€ìˆ˜ëª… ì‚¬ìš©
    st.session_state.selected_business_name_stored = selected_business_name_from_selectbox
    # current_guideline_nameì´ ì‹¤ì œ ì‚¬ìš©ë˜ëŠ” ì‚¬ì—…ëª… (ë¡œê¹…ì— ì´ ê°’ì„ ì‚¬ìš©)
    st.session_state.current_guideline_name = selected_business_name_from_selectbox 
    st.session_state.current_guideline_path = GUIDELINE_FILES[selected_business_name_from_selectbox]
else: 
    st.session_state.current_guideline_path = None
    st.session_state.current_guideline_name = None # ì‚¬ì—…ëª…ì´ ì„ íƒë˜ì§€ ì•Šì€ ê²½ìš° Noneìœ¼ë¡œ ì„¤ì •
    st.warning("ì‚¬ì—…ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
    st.stop()

active_guideline_rag_chain = None
if st.session_state.current_guideline_path and st.session_state.current_guideline_name:
    guideline_vector_store = get_cached_guideline_vector_store(
        embeddings_model_global, 
        st.session_state.current_guideline_path, 
        st.session_state.current_guideline_name # ì‚¬ì—…ëª… ì „ë‹¬
    )

    if guideline_vector_store:
        active_guideline_rag_chain = get_rag_chain_for_guideline(
            guideline_vector_store, 
            llm_global, 
            st.session_state.current_guideline_name # ì‚¬ì—…ëª… ì „ë‹¬
        )
        if active_guideline_rag_chain:
            st.success(f"'{st.session_state.current_guideline_name}' ì§€ì¹¨ ê¸°ë°˜ RAG ì²´ì¸ ì¤€ë¹„ ì™„ë£Œ.")
        else:
            st.error(f"'{st.session_state.current_guideline_name}' ì§€ì¹¨ RAG ì²´ì¸ì„ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.error(f"'{st.session_state.current_guideline_name}' ì§€ì¹¨ ë²¡í„° ì €ì¥ì†Œë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
else:
    st.info("ë¨¼ì € ê²€í†  ê¸°ì¤€ì´ ë  ì‚¬ì—…ì„ ì„ íƒí•˜ê³  API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

st.markdown("---")
st.subheader("1. ê¸°ì—… ì œì¶œ ë¬¸ì„œ ìë™ ê²€í† ")
if st.session_state.current_guideline_name:
    st.caption(f"ì—…ë¡œë“œëœ ë¬¸ì„œì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ '{st.session_state.current_guideline_name}'ì˜ íšŒê³„ ì§€ì¹¨ì— ë§ëŠ”ì§€ ìë™ ê²€í†  ì˜ê²¬ì„ ì œì‹œí•©ë‹ˆë‹¤.")
else:
    st.caption("ì—…ë¡œë“œëœ ë¬¸ì„œì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì„ íƒëœ íšŒê³„ ì§€ì¹¨ì— ë§ëŠ”ì§€ ìë™ ê²€í†  ì˜ê²¬ì„ ì œì‹œí•©ë‹ˆë‹¤.")

uploaded_file_for_review = st.file_uploader(
    "ê²€í† í•  ê¸°ì—… ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (txt, pdf, xlsx, xls, docx, doc, csv)",
    type=["txt", "pdf", "xlsx", "xls", "docx", "doc", "csv"],
    key="auto_review_uploader"
)

current_review_config_key = (
    uploaded_file_for_review.name if uploaded_file_for_review else None,
    st.session_state.get("current_guideline_path")
)

if "last_review_config_key_processed" not in st.session_state:
    st.session_state.last_review_config_key_processed = None
if "auto_review_output" not in st.session_state:
    st.session_state.auto_review_output = None

if uploaded_file_for_review is not None and active_guideline_rag_chain and st.session_state.current_guideline_name: # ì‚¬ì—…ëª… í™•ì¸ ì¶”ê°€
    if st.session_state.last_review_config_key_processed != current_review_config_key:
        st.session_state.auto_review_output = None 
        st.session_state.last_review_config_key_processed = current_review_config_key

        st.info(f"'{uploaded_file_for_review.name}' íŒŒì¼ ìë™ ê²€í† ë¥¼ '{st.session_state.current_guideline_name}' ì§€ì¹¨ì— ë”°ë¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        temp_file_path_for_upload = save_uploaded_file_to_temp(uploaded_file_for_review)
        
        if temp_file_path_for_upload:
            st.info(f"ì—…ë¡œë“œëœ ê²€í† ìš© íŒŒì¼ ë¡œë”© ì‹œë„: {uploaded_file_for_review.name}")
            uploaded_docs_content_list = load_document_from_local_path(temp_file_path_for_upload, uploaded_file_for_review.name)
            
            if uploaded_docs_content_list:
                content_to_review = ""
                for doc_idx, doc in enumerate(uploaded_docs_content_list[:2]): 
                    content_to_review += f"[ë¬¸ì„œ {doc_idx+1} ì‹œì‘]\n"
                    content_to_review += str(doc.page_content)[:1000] + "\n" 
                    content_to_review += f"[ë¬¸ì„œ {doc_idx+1} ë]\n...\n"
                
                if content_to_review.strip(): 
                    auto_review_question = f"ë‹¤ìŒì€ ê¸°ì—…ì´ ì œì¶œí•œ ë¬¸ì„œì˜ ì¼ë¶€ ë‚´ìš©ì…ë‹ˆë‹¤. ì´ ë‚´ìš©ì´ '{st.session_state.current_guideline_name}' ì§€ì¹¨ì— ë¶€í•©í•˜ëŠ”ì§€, íŠ¹ë³„íˆ ì£¼ì˜í•´ì•¼ í•  ì ì´ë‚˜ í™•ì¸ì´ í•„ìš”í•œ ì‚¬í•­ì´ ìˆëŠ”ì§€ ê²€í† í•´ì£¼ì„¸ìš”:\n\n---\n{content_to_review.strip()}\n---"
                    
                    with st.spinner("ìë™ ê²€í†  ì˜ê²¬ ìƒì„± ì¤‘..."):
                        try:
                            with get_openai_callback() as cb:
                                response = active_guideline_rag_chain.invoke({"input": auto_review_question})
                                cost_usd = cb.total_cost
                                total_tokens = cb.total_tokens
                                prompt_tokens = cb.prompt_tokens
                                completion_tokens = cb.completion_tokens
                                
                                log_token_usage(
                                    business_name=st.session_state.current_guideline_name, # ì‚¬ì—…ëª… ì „ë‹¬
                                    model_name=llm_global.model_name,
                                    prompt_tokens=prompt_tokens,
                                    completion_tokens=completion_tokens,
                                    total_tokens=total_tokens,
                                    cost_usd=cost_usd,
                                    api_call_tag="auto_review_guideline"
                                )
                                cost_krw = cost_usd * USD_TO_KRW_EXCHANGE_RATE

                            st.session_state.auto_review_output = {
                                "file_name": uploaded_file_for_review.name,
                                "guideline_name": st.session_state.current_guideline_name,
                                "answer": response["answer"],
                                "cost_info": f"ì´ ì‚¬ìš© í† í°: {total_tokens}, ì˜ˆìƒ ë¹„ìš© (USD): ${cost_usd:.6f}, (KRW): â‚©{cost_krw:,.2f}"
                            }
                        except Exception as e:
                            st.error(f"ìë™ ê²€í†  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                            st.session_state.auto_review_output = None 
                else:
                    st.warning("ì—…ë¡œë“œëœ ë¬¸ì„œì—ì„œ ê²€í† í•  ë‚´ìš©ì„ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            else:
                st.error(f"ì—…ë¡œë“œëœ ë¬¸ì„œ ë‚´ìš©ì„ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ({uploaded_file_for_review.name})")
            
            if os.path.exists(temp_file_path_for_upload):
                try:
                    os.remove(temp_file_path_for_upload)
                except Exception as e:
                    st.warning(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ ({temp_file_path_for_upload}): {e}")
        else:
            st.error("ì—…ë¡œë“œëœ íŒŒì¼ì„ ì„ì‹œ ì €ì¥í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    if st.session_state.auto_review_output:
        output = st.session_state.auto_review_output
        if output["file_name"] == uploaded_file_for_review.name and \
           output["guideline_name"] == st.session_state.current_guideline_name:
            st.subheader(f"'{output['file_name']}' ìë™ ê²€í†  ê²°ê³¼ ({output['guideline_name']} ê¸°ì¤€):")
            st.markdown(output["answer"], unsafe_allow_html=True) 
            with st.expander("ìë™ ê²€í†  ë¹„ìš© ì •ë³´ (ì´ë²ˆ ìš”ì²­)"):
                st.text(output["cost_info"])
        else: 
            st.info("ìƒˆë¡œìš´ íŒŒì¼ ë˜ëŠ” ì§€ì¹¨ì´ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤. ìë™ ê²€í† ê°€ ë‹¤ì‹œ ì‹¤í–‰ë©ë‹ˆë‹¤.")

elif uploaded_file_for_review is None:
    st.info("ìë™ ê²€í† ë¥¼ ìœ„í•´ ê¸°ì—… ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
elif not active_guideline_rag_chain:
    st.warning("ìë™ ê²€í† ë¥¼ ìœ„í•œ ì§€ì¹¨ RAG ì²´ì¸ì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. APIí‚¤ì™€ ì‚¬ì—… ì„ íƒì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
elif not st.session_state.current_guideline_name: # ì‚¬ì—…ëª…ì´ ì„ íƒë˜ì§€ ì•Šì€ ê²½ìš°
    st.warning("ìë™ ê²€í† ë¥¼ ì‹¤í–‰í•˜ê¸° ì „ì— ë¨¼ì € ì‚¬ì—…ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")


st.markdown("---")
st.subheader("2. ì—…ë¡œë“œëœ ë¬¸ì„œì— ëŒ€í•´ ì§ì ‘ ì§ˆì˜ì‘ë‹µ")
st.caption("ìœ„ 'ìë™ ê²€í† ' ì„¹ì…˜ì—ì„œ ì‚¬ìš©ëœ ë™ì¼í•œ ì—…ë¡œë“œ íŒŒì¼ì„ ëŒ€ìƒìœ¼ë¡œ ì§ì ‘ ì§ˆë¬¸í•˜ê³  ë‹µë³€ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

uploaded_doc_qa_chain = None
# ì‚¬ì—…ëª…ì´ ì„ íƒë˜ì—ˆê³ , íŒŒì¼ì´ ì—…ë¡œë“œ ë˜ì—ˆì„ ë•Œë§Œ ì´ ì„¹ì…˜ í™œì„±í™”
if uploaded_file_for_review is not None and st.session_state.current_guideline_name: 
    current_uploaded_file_key_for_qa_tuple = (
        uploaded_file_for_review.name,
        uploaded_file_for_review.size,
        getattr(uploaded_file_for_review, 'last_modified', uploaded_file_for_review.size) 
    )
    
    vs_session_key = f"uploaded_vs_{current_uploaded_file_key_for_qa_tuple}_{OPENAI_API_KEY_INPUT}"
    chain_session_key = f"uploaded_chain_{current_uploaded_file_key_for_qa_tuple}_{OPENAI_API_KEY_INPUT}"

    if chain_session_key not in st.session_state: 
        st.info(f"'{uploaded_file_for_review.name}' ë¬¸ì„œ ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ ì¤€ë¹„ ì¤‘ ({st.session_state.current_guideline_name} ì‚¬ì—… ì»¨í…ìŠ¤íŠ¸)...")
        temp_file_path_for_qa = save_uploaded_file_to_temp(uploaded_file_for_review) 
        
        if temp_file_path_for_qa:
            st.info(f"ì—…ë¡œë“œëœ Q&Aìš© íŒŒì¼ ë¡œë”© ì‹œë„: {uploaded_file_for_review.name}")
            uploaded_documents_for_qa = load_document_from_local_path(temp_file_path_for_qa, uploaded_file_for_review.name)
            if uploaded_documents_for_qa:
                vector_store_for_qa = build_generic_vector_store_for_qa(
                    _docs_for_qa=uploaded_documents_for_qa, 
                    _embeddings_model=embeddings_model_global,
                    file_name_for_log=uploaded_file_for_review.name,
                    cache_key_tuple=current_uploaded_file_key_for_qa_tuple 
                )
                st.session_state[vs_session_key] = vector_store_for_qa 

                if vector_store_for_qa:
                    chain = get_document_qa_rag_chain(
                        vector_store_for_qa,
                        llm_global,
                        uploaded_file_for_review.name
                    )
                    st.session_state[chain_session_key] = chain 
                    if chain:
                        st.success(f"'{uploaded_file_for_review.name}' ë¬¸ì„œ ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ ì¤€ë¹„ ì™„ë£Œ.")
                    else:
                        st.error(f"'{uploaded_file_for_review.name}' ë¬¸ì„œ Q&A ì²´ì¸ ìƒì„± ì‹¤íŒ¨.")
                else: 
                    if chain_session_key in st.session_state: del st.session_state[chain_session_key]
            else: 
                st.error(f"ì—…ë¡œë“œëœ Q&Aìš© ë¬¸ì„œ ë‚´ìš©ì„ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ({uploaded_file_for_review.name})")
                if vs_session_key in st.session_state: del st.session_state[vs_session_key]
                if chain_session_key in st.session_state: del st.session_state[chain_session_key]

            if os.path.exists(temp_file_path_for_qa):
                try:
                    os.remove(temp_file_path_for_qa)
                except Exception as e:
                    st.warning(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ ({temp_file_path_for_qa}): {e}")
        else: 
            if vs_session_key in st.session_state: del st.session_state[vs_session_key]
            if chain_session_key in st.session_state: del st.session_state[chain_session_key]
            st.error("Q&Aë¥¼ ìœ„í•œ ì—…ë¡œë“œ íŒŒì¼ ì„ì‹œ ì €ì¥ ì‹¤íŒ¨.")

    uploaded_doc_qa_chain = st.session_state.get(chain_session_key)

    if uploaded_doc_qa_chain:
        user_question_for_uploaded_doc = st.text_input(
            f"'{uploaded_file_for_review.name}' ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš” ({st.session_state.current_guideline_name} ì‚¬ì—… ê´€ë ¨):",
            key=f"user_question_direct_uploaded_{uploaded_file_for_review.name}_{st.session_state.current_guideline_name}" 
        )
        if user_question_for_uploaded_doc:
            with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                try:
                    with get_openai_callback() as cb:
                        response = uploaded_doc_qa_chain.invoke({"input": user_question_for_uploaded_doc})
                        cost_usd = cb.total_cost
                        total_tokens = cb.total_tokens
                        prompt_tokens = cb.prompt_tokens
                        completion_tokens = cb.completion_tokens

                        log_token_usage(
                            business_name=st.session_state.current_guideline_name, # ì‚¬ì—…ëª… ì „ë‹¬
                            model_name=llm_global.model_name,
                            prompt_tokens=prompt_tokens,
                            completion_tokens=completion_tokens,
                            total_tokens=total_tokens,
                            cost_usd=cost_usd,
                            api_call_tag="qa_uploaded_doc"
                        )
                        cost_krw = cost_usd * USD_TO_KRW_EXCHANGE_RATE

                    st.subheader("ë‹µë³€:")
                    st.markdown(response["answer"], unsafe_allow_html=True) 
                    if "context" in response and response["context"]:
                        with st.expander("ì°¸ê³ í•œ ì—…ë¡œë“œ ë¬¸ì„œ ë‚´ìš© (ì¼ë¶€)"):
                            for i, doc_ctx in enumerate(response["context"][:2]): 
                                st.write(f"**ì¶œì²˜ {i+1} (ì†ŒìŠ¤: {doc_ctx.metadata.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ')})**")
                                st.caption(doc_ctx.page_content[:300] + "...")
                    with st.expander("ë¹„ìš© ì •ë³´ (ì´ë²ˆ ìš”ì²­)"):
                        st.text(f"ì´ ì‚¬ìš© í† í°: {total_tokens}, ì˜ˆìƒ ë¹„ìš© (USD): ${cost_usd:.6f}, (KRW): â‚©{cost_krw:,.2f}")
                except Exception as e:
                    st.error(f"ì§ì ‘ ì§ˆì˜ì‘ë‹µ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    elif uploaded_file_for_review is not None : 
        st.warning("ì—…ë¡œë“œëœ ë¬¸ì„œì— ëŒ€í•œ ì§ˆì˜ì‘ë‹µ ê¸°ëŠ¥ì´ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ì´ˆê¸°í™” ì¤‘ì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

elif not st.session_state.current_guideline_name:
     st.info("ë¬¸ì„œ ì§ˆì˜ì‘ë‹µì„ ìœ„í•´ ë¨¼ì € ì‚¬ì—…ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
else: # uploaded_file_for_review is None but business_name is selected
    st.info("ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ë©´ í•´ë‹¹ ë¬¸ì„œì— ëŒ€í•œ ìë™ ê²€í†  ë° ì§ì ‘ ì§ˆì˜ì‘ë‹µ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")


st.markdown("---")
st.subheader("3. ì§€ì¹¨ ë¬¸ì„œ ì§ì ‘ ì§ˆì˜ì‘ë‹µ")

if active_guideline_rag_chain and st.session_state.current_guideline_name:
    st.caption(f"'{st.session_state.current_guideline_name}' ì§€ì¹¨ ë‚´ìš©ì— ëŒ€í•´ ì§ì ‘ ì§ˆë¬¸í•˜ê³  ë‹µë³€ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    user_question_for_guideline = st.text_input(
        f"'{st.session_state.current_guideline_name}' ì§€ì¹¨ ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”:",
        key=f"user_question_guideline_direct_{st.session_state.current_guideline_name}"
    )

    if user_question_for_guideline:
        with st.spinner(f"'{st.session_state.current_guideline_name}' ì§€ì¹¨ ê¸°ë°˜ ë‹µë³€ ìƒì„± ì¤‘..."):
            try:
                with get_openai_callback() as cb:
                    input_for_guideline_qna = f"ë‹¤ìŒì€ '{st.session_state.current_guideline_name}' ì§€ì¹¨ì— ëŒ€í•œ ì§ì ‘ì ì¸ ì§ˆë¬¸ì…ë‹ˆë‹¤: {user_question_for_guideline}"
                    response = active_guideline_rag_chain.invoke({"input": input_for_guideline_qna})
                    cost_usd = cb.total_cost
                    total_tokens = cb.total_tokens
                    prompt_tokens = cb.prompt_tokens
                    completion_tokens = cb.completion_tokens

                    log_token_usage(
                        business_name=st.session_state.current_guideline_name, # ì‚¬ì—…ëª… ì „ë‹¬
                        model_name=llm_global.model_name,
                        prompt_tokens=prompt_tokens,
                        completion_tokens=completion_tokens,
                        total_tokens=total_tokens,
                        cost_usd=cost_usd,
                        api_call_tag="qa_guideline_direct"
                    )
                    cost_krw = cost_usd * USD_TO_KRW_EXCHANGE_RATE
                
                st.subheader("ë‹µë³€:")
                st.markdown(response["answer"], unsafe_allow_html=True) 
                
                if "context" in response and response["context"]:
                    with st.expander("ì°¸ê³ í•œ ì§€ì¹¨ ë‚´ìš© (ì¼ë¶€)"):
                        for i, doc_ctx in enumerate(response["context"][:3]): 
                            source_name_display = doc_ctx.metadata.get('source', st.session_state.current_guideline_name)
                            st.write(f"**ì¶œì²˜ {i+1} (ë¬¸ì„œ: {source_name_display})**")
                            st.caption(doc_ctx.page_content[:500] + "...") 
                
                with st.expander("ë¹„ìš© ì •ë³´ (ì´ë²ˆ ìš”ì²­)"):
                     st.text(f"ì´ ì‚¬ìš© í† í°: {total_tokens}, ì˜ˆìƒ ë¹„ìš© (USD): ${cost_usd:.6f}, (KRW): â‚©{cost_krw:,.2f}")
            except Exception as e:
                st.error(f"'{st.session_state.current_guideline_name}' ì§€ì¹¨ ì§ì ‘ ì§ˆì˜ì‘ë‹µ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
elif not st.session_state.current_guideline_name:
     st.info("ë¨¼ì € ê²€í†  ê¸°ì¤€ì´ ë  ì‚¬ì—…ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
else: # active_guideline_rag_chain is None (and business_name might be selected)
    st.warning(f"'{st.session_state.current_guideline_name}' ì§€ì¹¨ì— ëŒ€í•œ RAG ì²´ì¸ì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. APIí‚¤ì™€ ì‚¬ì—… ì„ íƒì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

# --- (ì„ íƒì ) ë¡œê¹…ëœ ë°ì´í„° í™•ì¸ UI ---
st.sidebar.markdown("---")
st.sidebar.subheader("ëˆ„ì  ì‚¬ìš©ëŸ‰ í™•ì¸ (ìµœê·¼ 10ê±´)")
show_logs_button = st.sidebar.button("ì‚¬ìš©ëŸ‰ ë¡œê·¸ ë³´ê¸°")

if show_logs_button:
    try:
        conn = sqlite3.connect(DB_NAME)
        cursor = conn.cursor()
        # business_name ì»¬ëŸ¼ì„ í¬í•¨í•˜ì—¬ ì¡°íšŒ
        cursor.execute("SELECT timestamp, business_name, api_call_tag, model_name, total_tokens, cost_usd, cost_krw FROM usage_logs ORDER BY timestamp DESC LIMIT 10")
        logs = cursor.fetchall()
        conn.close()
        
        if logs:
            st.sidebar.markdown("`ì‹œê°„ | ì‚¬ì—…ëª… | í˜¸ì¶œíƒœê·¸ | ëª¨ë¸ | í† í° | USD | KRW`")
            for log_entry in logs:
                ts, biz_name, tag, model, tokens, usd, krw = log_entry
                # ì†Œìˆ˜ì  ë° None ê°’ ì²˜ë¦¬ ê°œì„ 
                usd_display = f"${usd:.4f}" if usd is not None else "N/A"
                krw_display = f"â‚©{krw:,.0f}" if krw is not None else "N/A"
                tag_display = tag if tag else "N/A"
                biz_name_display = biz_name if biz_name else "N/A"

                st.sidebar.text(f"{ts[:19]} | {biz_name_display} | {tag_display} | {model} | T:{tokens} | {usd_display} | {krw_display}")
        else:
            st.sidebar.info("ê¸°ë¡ëœ ì‚¬ìš© ë‚´ì—­ì´ ì—†ìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        st.sidebar.error(f"ë¡œê·¸ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")